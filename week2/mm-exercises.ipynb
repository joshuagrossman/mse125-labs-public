{"cells": [{"cell_type": "markdown", "id": "1dbf2241-1dfc-4d6f-9de0-9949db4c0307", "metadata": {"id": "1dbf2241-1dfc-4d6f-9de0-9949db4c0307"}, "source": ["# HW2 Lab: Introduction to inference with M&M's and helmets"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "d3d7eeb0-9bdf-4d29-8c3e-fcd0b69bd7d3", "metadata": {"id": "d3d7eeb0-9bdf-4d29-8c3e-fcd0b69bd7d3"}, "source": ["<img src=\"img/mm-helmet.jpg\" alt= \u201cm&m-helmet\u201d width=\"300\" />\n", "\n", "\u2757\u2757\u2757 **Make sure to save a copy of this notebook to your Google Drive so your work isn't lost.**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "-zEQLGmS23nb", "metadata": {"id": "-zEQLGmS23nb"}, "source": ["## 0. Introduction and Set up"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "64b167c1", "metadata": {"id": "64b167c1"}, "source": ["### Introduction\n", "\n", "In the first half of this notebook, we'll use `R` to learn about statistical inference using M&Ms data that we generated in class. In the second half of the notebook, we'll compare and contrast the M&Ms activity with the helmet-counting activity.\n", "\n", "By the end of this notebook, you'll have foundational understanding of how to statistically reason about uncertainty, and how to question the validity of assumptions of common methods for inference."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "a536c0b0", "metadata": {"id": "a536c0b0"}, "source": ["### \u2705 Set up\n", "\n", "While the core `R` language contains many useful functions (e.g., `sum` and `sample`), there is vast functionality built on top of `R` by community members.\n", "\n", "Make sure to run the cell below. It imports additional useful functions and adjusts `R` settings."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "ddcf0f8d-c481-403e-adc1-f3c359abb2d8", "metadata": {"id": "ddcf0f8d-c481-403e-adc1-f3c359abb2d8", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Load in additional functions\n", "library(tidyverse)\n", "library(lubridate)\n", "\n", "# Use three digits past the decimal point\n", "options(digits = 3)\n", "\n", "# Format plots with a white background and dark features.\n", "theme_set(theme_bw())\n", "\n", "# Increase the default text size of plots.\n", "# If you are *not* working in Google Colab, we recommend commenting\n", "# out this line of code.\n", "theme_update(text = element_text(size = 20))\n", "\n", "# Increase the default plot width and height.\n", "# If you are *not* working in Google Colab, we recommend commenting\n", "# out this line of code.\n", "options(repr.plot.width=12, repr.plot.height=8)"]}, {"cell_type": "markdown", "id": "otcpGSjo2MXh", "metadata": {"id": "otcpGSjo2MXh"}, "source": ["## 1: Inference with M&Ms"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "88a78542-da8f-46cc-9df1-060b86b96573", "metadata": {"id": "88a78542-da8f-46cc-9df1-060b86b96573"}, "source": ["### 1.1: M&Ms data generating process"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "9c6804b1-a63e-471d-8ae1-8f9fab27ceca", "metadata": {"id": "9c6804b1-a63e-471d-8ae1-8f9fab27ceca"}, "source": ["Suppose M&M's bags are filled with candy by an unobserved machine. It might look something like this:"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "a25ed576-accb-4737-9251-0c5171ca57a1", "metadata": {"id": "a25ed576-accb-4737-9251-0c5171ca57a1"}, "source": ["<img src=\"img/factory.jpg\" alt= \u201cm&msfactory\u201d width=\"300\" />"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "2d824447-9345-42fe-b0d5-16d1abf82613", "metadata": {"id": "2d824447-9345-42fe-b0d5-16d1abf82613"}, "source": ["As experienced candy-connoisseurs and budding data scientists, suppose we're interested in an important question:\n", "\n", "- On average, what proportion of M&M's are primary colored (i.e., yellow, red, or blue)?\n", "\n", "In other words, we're interested in **inferring a property of an unobserved machine that randomly generates bags of M&Ms.**\n", "\n", "- If we designed the machine ourselves, then we wouldn't need the tools of statistical inference. We could just read off the setting for \"proportion of candies that are primary colored\".\n", "\n", "- Instead, all we observe is a single bag of M&M's. Our goal is to use this single bag to say something meaningful about the unknown factory setting.\n", "\n", "If you've seen the [The Wizard of Oz](https://www.youtube.com/watch?v=ivRKfwmgrHY), you might draw an analogy to the unobserved man behind the curtain controlling what Dorothy et al. observe:\n", "\n", "<img src=\"img/curtain.jpg\" alt= \u201cwizardofoz\u201d width=\"300\" />\n", "\n", "This HW will lead you through the process of using a single bag of M&M's (the *sample*) to infer properties of an unobserved M&M's machine (the *population*, or the *data-generating process*).\n", "\n", "> At this point, it's natural to worry that filling bags with candy is totally unrelated to your future career prospects. However, this setup is surprisingly common in industry settings.\n", ">\n", "> For example, suppose you're a product manager who is interested in understanding your customer base. If we survey a random sample of customers, we can think of the aggregate opinion of the entire customer base as the properties unobserved M&M's machine, and our survey results as the observed bag of M&M's.\n", ">\n", "> Same idea if you're a pollster trying to understand the fraction of all voters who identify as Republicans when all you get to observe is a small sample of voters.\n", ">\n", "> The methods taught in this notebook are used *constantly* by practitioners."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "31cc05da-d7b6-4ef4-9d6e-ac5ab330050c", "metadata": {"id": "31cc05da-d7b6-4ef4-9d6e-ac5ab330050c"}, "source": ["### 1.2: \ud83c\udf6c Generating the data"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "3eXtgGyz35SZ", "metadata": {"id": "3eXtgGyz35SZ"}, "source": ["If you attended Lecture 3 in person, you received a fun-sized bag of M&Ms. Before eating your M&Ms, you reported the count of M&Ms of each color."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "nTdA2eH63OcP", "metadata": {"id": "nTdA2eH63OcP"}, "source": ["##### **Exercise 1**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "c12eeacc-ce4a-415a-b3d7-c619b9767d1b", "metadata": {"id": "c12eeacc-ce4a-415a-b3d7-c619b9767d1b"}, "source": ["Report the count of your M&Ms in the code cell below.\n", "\n", "- Your data should have been emailed to you when you submitted the M&Ms data collection form.\n", "\n", "- If you do not have access to your M&Ms data, please locate it in the [aggregated data](https://jdgrossman.com/assets/mm_data.csv).\n", "\n", "- If you did not attend lecture, please use any student's data as your own."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "9ad694d5-eb90-439f-ae37-57c20ad3d846", "metadata": {"id": "9ad694d5-eb90-439f-ae37-57c20ad3d846", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["n_primary_colored = NA\n", "\n", "n_not_primary_colored = NA\n", "\n"]}, {"cell_type": "markdown", "id": "e7886e9e-f2ea-436d-8952-b173730233e1", "metadata": {"id": "e7886e9e-f2ea-436d-8952-b173730233e1"}, "source": ["### 1.3: \u261d\ufe0f Point estimates"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "85cef4e2-08e2-4c7a-9f9c-e6ebdd35dd4a", "metadata": {"id": "85cef4e2-08e2-4c7a-9f9c-e6ebdd35dd4a"}, "source": ["Our first objective is to provide a *point estimate*, or single best guess, of the *population* proportion of M&M's that are primary colored.\n", "\n", "- This is a setting on the M&M's machine that generated our bags. Remember, **the settings are not observed by us!** If they were observed, we wouldn't need the tools of inference."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "ISHPNrDX3sRI", "metadata": {"id": "ISHPNrDX3sRI"}, "source": ["##### **Exercise 2**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "BSv-qMmR3uFJ", "metadata": {"id": "BSv-qMmR3uFJ"}, "source": ["In the code cell below, provide a point estimate for the population proportion of M&M's that are primary colored."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "d7a2a4e4-6d4d-4c95-924e-5c2bb8b68db1", "metadata": {"id": "d7a2a4e4-6d4d-4c95-924e-5c2bb8b68db1", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Update the code below!\n", "\n", "my_point_estimate = NA\n", "\n", "print(my_point_estimate)"]}, {"cell_type": "markdown", "id": "30a27f72-52bc-4610-b149-eed754e8dc81", "metadata": {"id": "30a27f72-52bc-4610-b149-eed754e8dc81"}, "source": ["### 1.4: \u2753 Uncertainty"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "92927837-5311-409f-8955-668e2988db80", "metadata": {"id": "92927837-5311-409f-8955-668e2988db80"}, "source": ["Point estimates are often straightforward to calculate.\n", "\n", "Here's the problem: With only one bag of M&M's, how sure are you of your point estimate?\n", "\n", "- If you were instead given a different bag of M&M's, would you have had the same point estimate?\n", "\n", "- If you were instead given a smaller bag of M&M's, would you be less confident of your point estimate?\n", "\n", "- If you were instead given a Costco-sized plastic tub of M&M's, would you be more confident of your point estimate?\n", "\n", "What's going on here is **counterfactual reasoning**. In statistical inference, we need to think about **what could have happened in parallel universes**.\n", "\n", "The (unobserved) distribution of point estimates across these parallel universes is called a **sampling distribution**. This idea powers [frequentist statistical inference](https://en.wikipedia.org/wiki/Frequentist_inference#Relationship_with_other_approaches)!"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "317a0ec2-7117-4e2c-980b-fc6820cca054", "metadata": {"id": "317a0ec2-7117-4e2c-980b-fc6820cca054"}, "source": ["### 1.5: \ud83d\udc69\u200d\ud83d\ude80 Observing parallel universes?!"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "8074390c-03b8-4959-8b93-329bbc1d55b6", "metadata": {"id": "8074390c-03b8-4959-8b93-329bbc1d55b6"}, "source": ["We're in an exciting scenario where we can actually *observe parallel universes* where other point estimates were generated. Most of your classmates have also gathered data from their own small random sample of M&Ms.\n", "\n", "> It's important to stress that **this is an unrealistic scenario**. We normally only see one sample of data.\n", "\n", "If we plot the point estimates from all students in the course, we can get an approximation of the theoretical sampling distribution."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "-CDfJdfn4LtH", "metadata": {"id": "-CDfJdfn4LtH"}, "source": ["##### **Exercise 3**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "b1EDzZyr4N5R", "metadata": {"id": "b1EDzZyr4N5R"}, "source": ["Plot the distribution of your and your classmates's point estimates for the proportion of M&M's that are primary colored. Draw a vertical line on your plot indicating the value of your own point estimate.\n", "\n", "*Reminder*: Starting with this homework, we will expect to see plots that are appropriately formatted for readibility. The plotting tips in Lecture 2 are a helpful reference."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "a571c0a7-a02f-4b91-80f0-114d1f3ed92b", "metadata": {"id": "a571c0a7-a02f-4b91-80f0-114d1f3ed92b", "outputId": "22f8360c-799b-45eb-f9fe-3e71e54432d1", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code here!\n", "\n", "# The classwide M&Ms count data is stored at this URL. \n", "data_url = \"https://jdgrossman.com/assets/mm_data.csv\"\n", "\n"]}, {"cell_type": "markdown", "id": "8xRdCB2x4TfI", "metadata": {"id": "8xRdCB2x4TfI"}, "source": ["##### **Exercise 4**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "d150d4e5", "metadata": {"id": "d150d4e5"}, "source": ["Aggregate all of your classmates data into one giant \"super sample\" of M&Ms. Calculate the proportion of the \"super sample\" that is primary colored in the code cell below.\n", "\n", "Are you at all surprised by the result? If yes, what do you think could account for the discrepancy between your expectation and reality? Using a comment in the code cell below, answer in no more than three sentences.\n", "\n", "> Given approximately 120 rows of data and 15 M&Ms per bag, our super sample has nearly 2,000 M&Ms.\n", ">\n", "> Under an assumption of true randomness, the proportion you calculate in this exercise should be very close to the true proportion of M&Ms that are primary colored (i.e., our estimand: the **fixed** but **unknown** setting at the factory that produced our bags!). For intuition, think about the maximum size of the standard error given a sample size of 2,000. It's tiny! \n", ">\n", "> Remember, though, this is a fictitious exercise. The whole point of inference is to use a single sample (i.e., one small bag of about 15 M&Ms) to say something meaningful about the estimand.\n", ">\n", "> For those interested in going down an M&Ms counting rabbit hole, [this article](https://qz.com/918008/the-color-distribution-of-mms-as-determined-by-a-phd-in-statistics) is a good start."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "649d4cab", "metadata": {"id": "649d4cab", "outputId": "a7ed90e6-0057-4ff8-bf89-6e2f963e98c6", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code here!\n", "\n"]}, {"cell_type": "markdown", "id": "e3240151-989f-42ce-9d1e-4bc6b48b029d", "metadata": {"id": "e3240151-989f-42ce-9d1e-4bc6b48b029d"}, "source": ["### 1.6: \ud83d\udcca Constructing parallel universes with statistics"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "7a6ffaef-be46-4be7-98ec-4d2b368526f3", "metadata": {"id": "7a6ffaef-be46-4be7-98ec-4d2b368526f3"}, "source": ["In the real world, we don't get to observe parallel universes. But, is there any way for us to say something meaningful about the estimand (i.e., the true proportion of primary colored M&Ms) using just a *single* sample of M&Ms?\n", "\n", "To start, we can derive the properties of our estimator $\\hat{p}$ analytically. It's time for notation!\n", "\n", "$p$: the *population* proportion of M&M's that are primary colored\n", "\n", "$\\hat{p}$: the *sample* proportion of M&M's that are primary colored\n", "\n", "> When you see a $\\hat{hat}$ on a variable, it usually means it's an estimate for the same variable without the hat.\n", "\n", "Let's also assume that an M&M's color is a random variable $X$, where each $X_i$ is generated i.i.d. (independently and identically) via a Bernoulli distribution with probability of success $p$. In other words,\n", "\n", "$$ X \\sim Bernoulli(p) $$\n", "\n", "$x=1$ denotes a primary colored M&M, and $x=0$ denotes a non-primary colored  M&M.\n", "\n", "As stated above, the sample proportion of primary colored M&M's $\\hat{p}$ has the following formula:\n", "\n", "$$\\hat{p} = \\frac{1}{N}\\sum_{i = 1}^{N}X_i$$\n", "\n", "From the [properties of a Bernoulli\n", "distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) we know that\n", "\n", "\\begin{align*}\n", "\\mathbb{E}_p(X_i) & = p \\\\\n", "\\mathrm{Var}_p(X_i) & = p(1-p) \\\\\n", "\\end{align*}\n", "\n", "where the subscript $_p$ in\n", "$\\mathbb{E}_p$ and $\\mathrm{Var}_p$ simply means that $p$ is fixed (i.e., it's _not_ random), and that you can use $p$ directly in the expression for the expectation.\n", "\n", "> Remember, though, even though $p$ is fixed, it's unknown. Estimating $p$, the population proportion of M&M's that are primary colored, is the whole point of our inference!"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "57bb2e81-8c95-4e25-bfe1-a59df642135a", "metadata": {"id": "57bb2e81-8c95-4e25-bfe1-a59df642135a"}, "source": ["#### 1.6.1: \ud83d\udcad The theoretical sampling distribution of $\\hat{p}$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "30fd8c16-67c4-4d23-9a44-4ef88a3b114e", "metadata": {"id": "30fd8c16-67c4-4d23-9a44-4ef88a3b114e"}, "source": ["Suppose we use $\\hat{p}$ to estimate $p$, as we've done above.\n", "\n", "1. What's the expected value of $\\hat{p}$?\n", "\n", "2. What's the variance of $\\hat{p}$? Note that the variance of $\\hat{p}$ is the square of its standard error."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "SujEQ0_f5DCG", "metadata": {"id": "SujEQ0_f5DCG"}, "source": ["Let's turn the statistical crank!\n", "\n", "##### \ud83c\udfaf The expected value of $\\hat{p}$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "e6c1c4b0-690c-4285-bfa5-9ae6f32cebae", "metadata": {"id": "e6c1c4b0-690c-4285-bfa5-9ae6f32cebae"}, "source": ["\n", "\n", "**Linearity of expectation** implies the following:\n", "\n", "$$\\mathbb{E} \\left( \\sum_{i=1}^n X_i \\right) = \\sum_{i=1}^n \\mathbb{E}(X_i)$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "b8ea7640-f30a-4967-bdf8-054f59e14560", "metadata": {"id": "b8ea7640-f30a-4967-bdf8-054f59e14560"}, "source": ["Thus,\n", "\n", "\\begin{align*}\n", "\\mathbb{E}_p(\\hat{p}) & = \\mathbb{E}_p\\left(\\frac{1}{N}\\sum_{i = 1}^{N}X_i\\right) \\\\\n", "  & = \\frac{1}{N}\\mathbb{E}_p\\left(\\sum_{i = 1}^{N}X_i\\right) \\\\\n", "  & = \\frac{1}{N}\\sum_{i = 1}^{N}\\mathbb{E}_p(X_i) \\\\\n", "  & = \\frac{1}{N}\\sum_{i = 1}^{N}p \\\\\n", "  & = \\frac{1}{N}Np \\\\\n", "  & = p\n", "\\end{align*}"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "3e41a79b-3b52-4163-a315-ea30195ffbec", "metadata": {"id": "3e41a79b-3b52-4163-a315-ea30195ffbec"}, "source": ["The expected value of $\\hat{p}$ is $p$.\n", "\n", "$\\hat{p}$ is therefore an *unbiased* estimator of $p$.\n", "\n", "In other words, the the mean of the theoretical sampling distribution of $\\hat{p}$ is identical to the estimand.\n", "\n", "> If an estimator is unbiased, it does not mean it will always be the same value as the estimand. The **average** value of an unbiased estimator across many random samples will be very close to the corresponding estimand."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "0b00d213-2d7d-4d0b-beaf-1c71c342bd81", "metadata": {"id": "0b00d213-2d7d-4d0b-beaf-1c71c342bd81"}, "source": ["##### \u2696\ufe0f The variance of $\\hat{p}$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "57992349-4b53-4eb9-a914-dfceb5607a9d", "metadata": {"id": "57992349-4b53-4eb9-a914-dfceb5607a9d"}, "source": ["If each $X_i$ is independently generated, then the following is true:\n", "\n", "$$\\mathrm{Var} \\left( \\sum_{i=1}^n X_i \\right) = \\sum_{i=1}^n \\mathrm{Var}(X_i)$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "67195497-e7e6-492d-90f7-0046026df2ba", "metadata": {"id": "67195497-e7e6-492d-90f7-0046026df2ba"}, "source": ["Thus,\n", "\n", "\\begin{align*}\n", "\\mathrm{Var}_p(\\hat{p})\n", "  & = \\mathrm{Var}_p\\left(\\frac{1}{N}\\sum_{i = 1}^{N}X_i\\right) \\\\\n", "  & = \\frac{1}{N^2}\\sum_{i = 1}^{N}\\mathrm{Var}_p(X_i) \\\\\n", "  & = \\frac{1}{N^2}Np(1-p) \\\\\n", "  & = \\frac{p(1-p)}{N}\n", "\\end{align*}\n", "\n", "and the standard error is:\n", "\n", "$$\\sqrt{\\mathrm{Var}_p(\\hat{p})} = \\sqrt{\\frac{p(1-p)}{N}}$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "ef34ed69-c259-40b3-9fe9-e2a872f346b2", "metadata": {"id": "ef34ed69-c259-40b3-9fe9-e2a872f346b2"}, "source": ["If we don't know $p$, how can we calculate the variance of $\\hat{p}$?\n", "\n", "We can't. We have to estimate $p$ using our point estimate, $\\hat{p}$.\n", "\n", "The estimated variance of $\\hat{p}$ is $\\frac{\\hat{p}(1-\\hat{p})}{n}$, and the estimated standard error is $\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "lVeaNeIw5Slx", "metadata": {"id": "lVeaNeIw5Slx"}, "source": ["##### **Exercise 5**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "6tVDGg4Z5avo", "metadata": {"id": "6tVDGg4Z5avo"}, "source": ["This exercise contains four parts."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "DFWPOL9g5iBM", "metadata": {"id": "DFWPOL9g5iBM"}, "source": ["**5 (a)**: In the M&Ms counting setting, what is the plain language interpretation of the standard error? Answer in no more than two sentences."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "6Z7Qsutv5nVu", "metadata": {"id": "6Z7Qsutv5nVu"}, "source": ["---\n", "\n", "*Your answer for 5(a) here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "M9DzavlT5yGo", "metadata": {"id": "M9DzavlT5yGo"}, "source": ["**5 (b)**: Using just your own sample of data, calculate the *estimated standard error* of the sampling distribution of $\\hat{p}$. Then, calculate the *true standard error* using our purported value of *p* obtained from the \"super sample\" (remember, in a realistic setting, *p* is not observed!). Finally, calculate the *empirical standard error* of the sampling distribution that we plotted above."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "923d479e-0a24-49fb-bb9f-00aff562f990", "metadata": {"id": "923d479e-0a24-49fb-bb9f-00aff562f990", "outputId": "0b0dd24e-10c9-485c-e9ec-72866ab8cd34", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code here!\n", "\n"]}, {"cell_type": "markdown", "id": "4SLB9bct55Dt", "metadata": {"id": "4SLB9bct55Dt"}, "source": ["**5 (c)**: Based on your results, do you feel comfortable using the estimated standard error from your single sample as an approximation of the true standard error? Why or why not? In a realistic setting, would we be able to compare the estimated standard error with the true standard error? Answer in no more than three sentences."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "tte49LIx5_c0", "metadata": {"id": "tte49LIx5_c0"}, "source": ["---\n", "\n", "*Your answer for 5c here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "6WXihzTb6GGb", "metadata": {"id": "6WXihzTb6GGb"}, "source": ["**5 (d)**: Why do you think the empirical standard error is different than the true standard error? Answer in no more than two sentences."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "eYxdLV_G6Iz6", "metadata": {"id": "eYxdLV_G6Iz6"}, "source": ["---\n", "\n", "*Your answer for 5d here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "9aa9b1f9-a13d-4055-8ad3-6a0a23714ab5", "metadata": {"id": "9aa9b1f9-a13d-4055-8ad3-6a0a23714ab5"}, "source": ["#### 1.6.2: \ud83d\udd14 The central limit theorem (CLT)"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "e95e2b08-ab58-435e-aa6d-47b6d2a7de7b", "metadata": {"id": "e95e2b08-ab58-435e-aa6d-47b6d2a7de7b"}, "source": ["Here's where things get spooky.\n", "\n", "Coarsely, if an estimator involves a summation of random variables, and we sample a sufficient number of data points i.i.d., then the sampling distribution of the estimator will approximate a normal distribution, *regardless of the shape of the underlying data distribution*.\n", "\n", "> In other words, normality can \"spring forth\" from distributions that are not necessarily normal. I like to think of the CLT's role in frequentist statistics as similar to gravity's role in physics. The CLT is a big deal!\n", "\n", "In our case, the implied data distribution is Bernoulli, where the probability of success is the true proportion of primary colored M&M's."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "f9a52be5", "metadata": {"id": "f9a52be5"}, "source": ["In order for the CLT to hold in our setting, the following must be true:\n", "\n", "1. The random variables denoting the color of each M&M should be independent and identically distributed.\n", "2. Our estimator should involve a sum of these random variables.\n", "3. `np >= 5` and `n(1-p) >= 5`, where `n` is the size of the sample and `p` is the true population proportion. A heads up: Some sources report that `np >= 10` and `n(1-p) >= 10` is rule of thumb you should use. There is not singular agreement!\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "PIc3BGg76byQ", "metadata": {"id": "PIc3BGg76byQ"}, "source": ["##### **Exercise 6**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "123e972b", "metadata": {"id": "123e972b"}, "source": ["Are the requirements of the CLT satisfied in the M&Ms counting scenario? Address each requirement of the CLT with no more than one or two sentences (i.e., three to six sentences total)."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "2e7f6b22", "metadata": {"id": "2e7f6b22"}, "source": ["---\n", "\n", "*Your answer for Exercise 6 here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "a9aa2767-979c-43a9-94c4-2be29600882f", "metadata": {"id": "a9aa2767-979c-43a9-94c4-2be29600882f"}, "source": ["### 1.7: \ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1 Putting it all together\n", "\n", "The CLT allows us to construct normally-approximated confidence intervals for estimators that satisfy the CLT.\n", "\n", "> We have arrived at why we should care about everything we have learned above: With confidence intervals in hand, we can make statistically-informed industry decisions.\n", "\n", "In lecture, we saw that if\n", "\n", "$$\\hat{p}_n \\approx N(p, \\hat{\\text{se}}^2)$$\n", "\n", "and\n", "\n", "$$C_n = (\\hat{p}_n - z_{\\alpha/2}\\hat{\\text{se}}, \\ \\hat{p}_n + z_{\\alpha/2}\\hat{\\text{se}})$$\n", "\n", "then\n", "\n", "$$\\Pr(p \\in C_n) \\approx 1-\\alpha$$\n", "\n", "For a 95\\% confidence interval, $\\alpha=0.05$."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "hd_t-x9-6xc1", "metadata": {"id": "hd_t-x9-6xc1"}, "source": ["##### **Exercise 7**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "4e999720-bc3c-4ec6-acb5-9ecdb85e8e20", "metadata": {"id": "4e999720-bc3c-4ec6-acb5-9ecdb85e8e20"}, "source": ["This exercise has two parts.\n", "\n", "**7(a)**: Using your single M&M's sample and the formula for the estimated standard error of $\\hat{p}$, use the normal approximation to construct a 95% confidence interval for $p$ in the code cell below. **Make sure to print the bounds of your confidence interval**.\n"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "b480871e-767a-4292-84fc-4b18fce9a37e", "metadata": {"id": "b480871e-767a-4292-84fc-4b18fce9a37e", "outputId": "8a7f3b16-8dcd-40d5-ad4f-9a78118a39c9", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code for 7(a) here!\n", "\n"]}, {"cell_type": "markdown", "id": "3e1eab6b", "metadata": {}, "source": ["**7(b)**: Interpret your confidence interval in no more than one sentence. Does your interval contain the value of $p$ that we calculated from the super sample?  Write your answer in the markdown (text) cell below."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "8oJt0tOv7Gzp", "metadata": {"id": "8oJt0tOv7Gzp"}, "source": ["---\n", "\n", "*Your written answer for Exercise 7(b) here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "ALw99oxc7LuQ", "metadata": {"id": "ALw99oxc7LuQ"}, "source": ["##### **Exercise 8**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "a1d0680e", "metadata": {"id": "a1d0680e"}, "source": ["This exercise has two parts.\n", "\n", "Repeat the previous exercise for each of your classmates' samples (i.e., construct $N$ normally-approximated confidence intervals, where $N$ is the number of students who submitted M&Ms data).\n", "\n", "**8(a)**: What fraction of the confidence intervals contain the purported value of $p$ that we calculated from the \"super sample\"? **Do your work in the code cell below and make sure to print out the fraction you calculated**."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "8b585490", "metadata": {"id": "8b585490", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code for 8(a) here!\n", "\n"]}, {"cell_type": "markdown", "id": "14a57459", "metadata": {}, "source": ["**8(b)**: If the data generating process (DGP) was correct and all assumptions of the CLT were sufficiently satisfied, what would you expect this fraction to be? Answer in no more than two sentences in the markdown (text) cell below."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "b2VYpJDB7kJb", "metadata": {"id": "b2VYpJDB7kJb"}, "source": ["---\n", "\n", "*Your written answer for Exercise 8(b) here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "jW2ldX_L8Fce", "metadata": {"id": "jW2ldX_L8Fce"}, "source": ["##### **Exercise 9**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "fc512ca0", "metadata": {"id": "fc512ca0"}, "source": ["This exercise has two parts.\n", "\n", "**9(a)**: Repeat the coding portions of the two previous exercises (8a and 8b), but instead of using the *estimated standard error* for each confidence interval, use the *empirical standard error* calculated from the sampling distribution of the entire class's estimates. "], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "9a089716", "metadata": {"id": "9a089716", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code for 9(a) here!\n", "\n"]}, {"cell_type": "markdown", "id": "e1cefa1b", "metadata": {}, "source": ["**9(b)**: How does the fraction calculated in this exercise compare with the fraction calculated in the previous exercise? What might account for the discrepancy? Answer in no more than two sentences in the markdown cell below."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "xHgDekhx8zoh", "metadata": {"id": "xHgDekhx8zoh"}, "source": ["---\n", "\n", "*Your written answer for 9(b) here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "Q-JKPnW88Io7", "metadata": {"id": "Q-JKPnW88Io7"}, "source": ["##### Exercise 10"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "79019513", "metadata": {"id": "79019513"}, "source": ["Repeat the coding portions of Exercises 8 and 9 above, but construct 80% confidence intervals instead of 95% confidence intervals. How have your results changed? Answer in no more than three sentences."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "d62cc711", "metadata": {"id": "d62cc711", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code to repeat Exercise 8 here!\n", "\n"]}, {"cell_type": "code", "execution_count": 0, "id": "Iq8WLqxO9Au0", "metadata": {"id": "Iq8WLqxO9Au0", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Your code to repeat Exercise 9 here!\n", "\n"]}, {"cell_type": "markdown", "id": "ZS6Ou-ok9Bn2", "metadata": {"id": "ZS6Ou-ok9Bn2"}, "source": ["---\n", "\n", "*Your written answer for Exercise 10 here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "3aad7f4d", "metadata": {"id": "3aad7f4d"}, "source": ["## 2. \ud83e\ude96 Transitioning from M&Ms to helmets"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "gvA32R-c922M", "metadata": {"id": "gvA32R-c922M"}, "source": ["##### **Exercise 11**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "-6IvIxDB90sJ", "metadata": {"id": "-6IvIxDB90sJ"}, "source": ["For each of the elements of the M&Ms counting exercise listed below, identify the corresponding element from the helmet counting exercise. \n", "\n", "1. Your bag of M&Ms.\n", "2. The M&Ms bags distributed to the entire class.\n", "3. The proportion of M&Ms in your bag that are primary colored.\n", "4. The hypothesized factory setting for the proportion of M&Ms that are primary colored.\n", "5. The factory process that generates M&Ms."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "4e0c2c1d", "metadata": {"id": "4e0c2c1d"}, "source": ["---\n", "\n", "*Your answer for Exercise 11 here*\n", "\n", "\n", "---"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "10qeDnkd99PW", "metadata": {"id": "10qeDnkd99PW"}, "source": ["##### **Exercise 12**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "id": "5805f817", "metadata": {"id": "5805f817"}, "source": ["Redo Exercises 1\u201310 using the helmet-counting data from the entire class. This data will be posted to the course website by Monday, April 15, the date we will have received most submissions.\n", "\n", "Finally, in five to ten sentences, compare the M&Ms exercise to the helmet-counting exercise. Below are some questions you might think about, but don't feel limited to the listed questions, or feel compelled to answer all of them. Ultimately, your response should probe the extent to which the assumptions of the M&Ms and helmet counting scenarios are reasonably satisified.\n", "\n", "- How does the timing of the sampling differ across the two scenarios, and how could this affect the results? \n", "- How does the magnitude of the sample size differ across the scenarios, and how could this affect the results? \n", "- How does the consistency of the sizes of the samples differ across the scenarios, and how could this affect the results?\n", "- Are the samples in each exercise truly random?\n", "- Are the samples in each exercise truly independent?\n", "- Do you think the DGP in each scenario is reasonable?\n", "- How do these two scenarios compare to a political polling scenario, or a customer surveying scenario?\n", "\n", "To answer this question, add code and Markdown cells below, and format them nicely.\n", "\n", "> Make it easy for the grader to parse your results! As a reminder, poorly formatted assignments may be docked points at the discretion of the grader."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "h3MsO7jx-nOV", "metadata": {"executionInfo": {"elapsed": 301, "status": "ok", "timestamp": 1713037302791, "user": {"displayName": "Salil Goyal", "userId": "15611659033161181264"}, "user_tz": 420}, "id": "h3MsO7jx-nOV", "vscode": {"languageId": "r"}}, "outputs": [], "source": ["# Feel free to create additional code cells as needed for this exercise"]}, {"cell_type": "markdown", "id": "f27530a8", "metadata": {"id": "f27530a8"}, "source": ["---\n", "\n", "*Your 5-10 sentences for comparing M&Ms exercise to helmet-count exercise here*\n", "\n", "---"], "execution_count": 0, "outputs": []}], "metadata": {"colab": {"collapsed_sections": ["-zEQLGmS23nb", "a536c0b0", "otcpGSjo2MXh", "88a78542-da8f-46cc-9df1-060b86b96573", "31cc05da-d7b6-4ef4-9d6e-ac5ab330050c", "nTdA2eH63OcP", "e7886e9e-f2ea-436d-8952-b173730233e1", "ISHPNrDX3sRI", "30a27f72-52bc-4610-b149-eed754e8dc81", "317a0ec2-7117-4e2c-980b-fc6820cca054", "-CDfJdfn4LtH", "8xRdCB2x4TfI", "e3240151-989f-42ce-9d1e-4bc6b48b029d", "57bb2e81-8c95-4e25-bfe1-a59df642135a", "SujEQ0_f5DCG", "e6c1c4b0-690c-4285-bfa5-9ae6f32cebae", "0b00d213-2d7d-4d0b-beaf-1c71c342bd81", "lVeaNeIw5Slx", "DFWPOL9g5iBM", "M9DzavlT5yGo", "4SLB9bct55Dt", "6WXihzTb6GGb", "9aa9b1f9-a13d-4055-8ad3-6a0a23714ab5", "PIc3BGg76byQ", "a9aa2767-979c-43a9-94c4-2be29600882f", "hd_t-x9-6xc1", "ALw99oxc7LuQ", "jW2ldX_L8Fce", "Q-JKPnW88Io7", "3aad7f4d", "gvA32R-c922M", "10qeDnkd99PW"], "provenance": []}, "kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "4.2.1"}}, "nbformat": 4, "nbformat_minor": 5}